#This is an evaluation of a successfully trained DQN agent after 500K training iterations (ran for about ~10mins) on the minimum yard environment
#The following training parameters were used:
num_iterations = 500000 #number of training iterations (e.g. play a number of steps and then train) 
collect_steps_per_iteration = 1 #how many steps to play in each training iteration
pretrain_steps = 10000 #number of steps to initialize the buffer with a pre trained policy
replay_buffer_max_length = 1000000
batch_size = 32
learning_rate = 2.5e-3
initial_e = 0.5 #initial epsilon
final_e = 0.01 #final epsilon
log_interval = 2 

#Final last few losses and metrics
490000 loss:136.27983INFO:absl:
                 NumberOfEpisodes = 24882
                 EnvironmentSteps = 490001
                 AverageReturn = 950.0
                 AverageEpisodeLength = 6.0
491000 loss:191.67194INFO:absl:
                 NumberOfEpisodes = 25037
                 EnvironmentSteps = 491001
                 AverageReturn = 946.0
                 AverageEpisodeLength = 6.400000095367432
492000 loss:136.07510INFO:absl:
                 NumberOfEpisodes = 25195
                 EnvironmentSteps = 492001
                 AverageReturn = 948.0
                 AverageEpisodeLength = 6.199999809265137
493000 loss:111.37715INFO:absl:
                 NumberOfEpisodes = 25348
                 EnvironmentSteps = 493001
                 AverageReturn = 921.0
                 AverageEpisodeLength = 8.899999618530273
494000 loss:222.12866INFO:absl:
                 NumberOfEpisodes = 25507
                 EnvironmentSteps = 494001
                 AverageReturn = 950.0
                 AverageEpisodeLength = 6.0
495000 loss:0.82783INFO:absl:
                 NumberOfEpisodes = 25665
                 EnvironmentSteps = 495001
                 AverageReturn = 946.0
                 AverageEpisodeLength = 6.400000095367432
496000 loss:55.54220INFO:absl:
                 NumberOfEpisodes = 25816
                 EnvironmentSteps = 496001
                 AverageReturn = 949.0
                 AverageEpisodeLength = 6.099999904632568
497000 loss:55.62747INFO:absl:
                 NumberOfEpisodes = 25978
                 EnvironmentSteps = 497001
                 AverageReturn = 950.0
                 AverageEpisodeLength = 6.0
498000 loss:55.57678INFO:absl:
                 NumberOfEpisodes = 26132
                 EnvironmentSteps = 498001
                 AverageReturn = 943.0
                 AverageEpisodeLength = 6.699999809265137
499000 loss:55.66095INFO:absl:
                 NumberOfEpisodes = 26290
                 EnvironmentSteps = 499001
                 AverageReturn = 944.0
                 AverageEpisodeLength = 6.599999904632568
499999 loss:0.2810

Period: 0
Track 1: ['m1']
Rack 2: []
Track 3: []
=============================
Action: [1, 2, 1]
Period: 1
Track 1: []
Rack 2: ['m1']
Track 3: []
=============================
Action: [2, 2, 1]
Period: 2
Track 1: []
Rack 2: ['m1']
Track 3: []
=============================
Action: [2, 2, 1]
Period: 3
Track 1: []
Rack 2: ['m1']
Track 3: []
=============================
Action: [2, 2, 1]
Period: 4
Track 1: []
Rack 2: ['M1']
Track 3: []
=============================
Action: [2, 1, 1]
Period: 5
Track 1: ['M1']
Rack 2: []
Track 3: []
=============================
Action: [1, 3, 1]
Period: 6
Track 1: []
Rack 2: []
Track 3: ['M1']
Period: 0
Track 1: ['m1']
Rack 2: []
Track 3: []
=============================
Action: [1, 2, 1]
Period: 1
Track 1: []
Rack 2: ['m1']
Track 3: []
=============================
Action: [2, 2, 1]
Period: 2
Track 1: []
Rack 2: ['m1']
Track 3: []
=============================
Action: [2, 2, 1]
Period: 3
Track 1: []
Rack 2: ['m1']
Track 3: []
=============================
Action: [2, 2, 1]
Period: 4
Track 1: []
Rack 2: ['M1']
Track 3: []
=============================
Action: [2, 1, 1]
Period: 5
Track 1: ['M1']
Rack 2: []
Track 3: []
=============================
Action: [1, 3, 1]
Period: 6
Track 1: []
Rack 2: []
Track 3: ['M1']
Period: 0
Track 1: ['m1']
Rack 2: []
Track 3: []
=============================
Action: [1, 2, 1]
Period: 1
Track 1: []
Rack 2: ['m1']
Track 3: []
=============================
Action: [2, 2, 1]
Period: 2
Track 1: []
Rack 2: ['m1']
Track 3: []
=============================
Action: [2, 2, 1]
Period: 3
Track 1: []
Rack 2: ['m1']
Track 3: []
=============================
Action: [2, 2, 1]
Period: 4
Track 1: []
Rack 2: ['M1']
Track 3: []
=============================
Action: [2, 1, 1]
Period: 5
Track 1: ['M1']
Rack 2: []
Track 3: []
=============================
Action: [1, 3, 1]
Period: 6
Track 1: []
Rack 2: []
Track 3: ['M1']
Period: 0
Track 1: ['m1']
Rack 2: []
Track 3: []
=============================
Action: [1, 2, 1]
Period: 1
Track 1: []
Rack 2: ['m1']
Track 3: []
=============================
Action: [2, 2, 1]
Period: 2
Track 1: []
Rack 2: ['m1']
Track 3: []
=============================
Action: [2, 2, 1]
Period: 3
Track 1: []
Rack 2: ['m1']
Track 3: []
=============================
Action: [2, 2, 1]
Period: 4
Track 1: []
Rack 2: ['M1']
Track 3: []
=============================
Action: [2, 1, 1]
Period: 5
Track 1: ['M1']
Rack 2: []
Track 3: []
=============================
Action: [1, 3, 1]
Period: 6
Track 1: []
Rack 2: []
Track 3: ['M1']
Period: 0
Track 1: ['m1']
Rack 2: []
Track 3: []
=============================
Action: [1, 2, 1]
Period: 1
Track 1: []
Rack 2: ['m1']
Track 3: []
=============================
Action: [2, 2, 1]
Period: 2
Track 1: []
Rack 2: ['m1']
Track 3: []
=============================
Action: [2, 2, 1]
Period: 3
Track 1: []
Rack 2: ['m1']
Track 3: []
=============================
Action: [2, 2, 1]
Period: 4
Track 1: []
Rack 2: ['M1']
Track 3: []
=============================
Action: [2, 1, 1]
Period: 5
Track 1: ['M1']
Rack 2: []
Track 3: []
=============================
Action: [1, 3, 1]
Period: 6
Track 1: []
Rack 2: []
Track 3: ['M1']
